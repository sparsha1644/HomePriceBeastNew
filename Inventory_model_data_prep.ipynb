{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c272cc-f57a-402e-b6cc-844745218ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee77cdec-d927-4095-bfae-9df6c52801e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"C:\\\\Users\\\\spars\\\\Documents\\\\Master\\\\JHU\\TML\\\\HomePriceBeastNew\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a335e0e2-4757-4a6f-b1a3-4f216d4dd4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_home_data_time_series = pd.read_csv(f\"{data_folder}merged_home_data_time_series.csv\", low_memory=False, thousands=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ac1921-fa2c-470e-a1ba-878660cbf10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_types_and_chunk(data, non_float_cols, date_col, dummy_cols):\n",
    "    for x in data.columns:\n",
    "        if x not in non_float_cols:\n",
    "            data[x] = pd.to_numeric(data[x])\n",
    "            \n",
    "    data = pd.get_dummies(data, columns = dummy_cols)\n",
    "\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    post_covid_frame = data[data[date_col] >= \"2020-03-01\"]\n",
    "    train_frame = data[data[date_col] < \"2019-12-01\"]\n",
    "    test_frame = data[((data[date_col] >= \"2019-12-01\") & (data[date_col] < \"2020-03-01\"))]\n",
    "    \n",
    "    return train_frame, test_frame, post_covid_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4a3de9-f543-4066-b0be-62cd49ad216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_float_cols = [\"state_code\", \"county_name\", \"period_begin\"]\n",
    "\n",
    "#convert these columns to encoding. \n",
    "dummy_cols = [\"state_code\"]\n",
    "\n",
    "train_frame, test_frame, post_covid_frame = transform_types_and_chunk(merged_home_data_time_series,\n",
    "                                 non_float_cols,\n",
    "                                 \"period_begin\",\n",
    "                                 dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857c3e24-09c9-4a75-b122-f403fbf130bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['county_name', 'period_begin', 'inventory', 'inventory_lag_1',\n",
       "       'inventory_lag_2', 'inventory_lag_3', 'inventory_lag_4',\n",
       "       'inventory_lag_5', 'inventory_lead_1', 'inventory_lead_2',\n",
       "       'inventory_lead_3', 'median_sale_price', 'median_sale_price_lag_1',\n",
       "       'median_sale_price_lag_2', 'median_sale_price_lag_3',\n",
       "       'median_sale_price_lag_4', 'median_sale_price_lag_5',\n",
       "       'R_INTERNATIONAL_MIG_2019', 'Unemployment_rate_2020',\n",
       "       'PCT_COLL_4_2015_19', 'PCT_COLL_1TO3_2000', 'PCT_HSD_Only_2000',\n",
       "       'R_NET_MIG_2019', 'Med_HH_Income_Percent_of_State_Total_2019',\n",
       "       'GQ_ESTIMATES_2019', 'N_POP_CHG_2019', 'INTERNATIONAL_MIG_2019',\n",
       "       'NET_MIG_2019', 'HSD_Only_2000', 'DOMESTIC_MIG_2019', 'RESIDUAL_2019',\n",
       "       'Deaths_2019', 'COLL_4_2000', 'POP_ESTIMATE_2019', 'LT_HSD_2015_19',\n",
       "       'COLL_1TO3_2000', 'Unemployed_2020', 'NATURAL_INC_2019',\n",
       "       'GQ_ESTIMATES_BASE_2010', 'Employed_2020', 'LT_HSD_2000',\n",
       "       'COLL_4_2015_19', 'HSD_Only_2015_19', 'COLL_1TO3_2015_19',\n",
       "       'Civilian_labor_force_2020', 'CENSUS_2010_POP', 'PCT_LT_HSD_2000',\n",
       "       'R_birth_2019', 'PCT_COLL_1TO3_2015_19', 'PCT_COLL_4_2000',\n",
       "       'Economic_typology_2015', 'R_death_2019', 'state_code_AK',\n",
       "       'state_code_AL', 'state_code_AR', 'state_code_AZ', 'state_code_CA',\n",
       "       'state_code_CO', 'state_code_CT', 'state_code_DC', 'state_code_DE',\n",
       "       'state_code_FL', 'state_code_GA', 'state_code_HI', 'state_code_IA',\n",
       "       'state_code_ID', 'state_code_IL', 'state_code_IN', 'state_code_KS',\n",
       "       'state_code_KY', 'state_code_LA', 'state_code_MA', 'state_code_MD',\n",
       "       'state_code_ME', 'state_code_MI', 'state_code_MN', 'state_code_MO',\n",
       "       'state_code_MS', 'state_code_NC', 'state_code_NE', 'state_code_NH',\n",
       "       'state_code_NJ', 'state_code_NM', 'state_code_NV', 'state_code_NY',\n",
       "       'state_code_OH', 'state_code_OK', 'state_code_OR', 'state_code_PA',\n",
       "       'state_code_RI', 'state_code_SC', 'state_code_TN', 'state_code_TX',\n",
       "       'state_code_UT', 'state_code_VA', 'state_code_VT', 'state_code_WA',\n",
       "       'state_code_WI', 'state_code_WV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74798a2e-45ce-4ca5-a94e-af7b8526f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_frame_to_numpy(df, remove_cols, target_prefix, related_prefix, J,H):\n",
    "    \n",
    "    #assemble lag variables.\n",
    "    y_lag_cols = [f'{target_prefix}_lag_{j}' for j in range(J,0,-1)]\n",
    "    y_lead_cols = [target_prefix] + [f'{target_prefix}_lead_{h}' for h in range(1,H+1,1)]    \n",
    "    x_rel_cols = [f'{related_prefix}_lag_{j}' for j in range(J,0,-1)]\n",
    "    other_cols = [x for x in df.columns if x not in y_lag_cols + y_lead_cols + x_rel_cols + remove_cols]\n",
    "    \n",
    "    def get_xvec_row(row):\n",
    "        x = np.array([row[y_lag_cols].values])\n",
    "        x = np.append(x,[row[x_rel_cols].values],axis=0)\n",
    "        stat_val = row[other_cols].values\n",
    "        stat_val = np.tile(stat_val,[J,1])\n",
    "        stat_val = np.transpose(stat_val)\n",
    "        x = np.append(x,stat_val,axis=0)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_yvec_row(row):\n",
    "        y = np.array([row[y_lead_cols].values])\n",
    "        \n",
    "        return y\n",
    "            \n",
    "    X = np.array(df.apply(get_xvec_row, axis = 1))\n",
    "    y = np.array(df.apply(get_yvec_row, axis = 1))\n",
    "    \n",
    "    return X,y\n",
    "    \n",
    "remove_cols = [\"county_name\", \"period_begin\"]\n",
    "target_prefix = 'inventory'\n",
    "related_prefix = 'median_sale_price'\n",
    "J=5\n",
    "H=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b6de84-1534-41c5-a213-eb07242c5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = convert_frame_to_numpy(train_frame, \n",
    "                                          remove_cols, \n",
    "                                          target_prefix, \n",
    "                                          related_prefix, \n",
    "                                          J,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268445cb-7e10-4aec-bf71-8429f20f865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = convert_frame_to_numpy(test_frame, \n",
    "                                        remove_cols, \n",
    "                                        target_prefix, \n",
    "                                        related_prefix, \n",
    "                                        J,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf23ce5-7635-41f6-aecc-bfd712da55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(a, size):\n",
    "    arr = iter(a)\n",
    "    for v in arr:\n",
    "        tmp = [ v ]\n",
    "        for i,v in zip( range( size - 1 ), arr ):\n",
    "            tmp.append( v )\n",
    "        yield tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbca175-18d1-4535-a620-e37adbe28815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack = list(chunks(np.vstack(X_train), 85))\n",
    "X_test_stack = list(chunks(np.vstack(X_test), 85))\n",
    "y_train_stack = np.expand_dims(np.vstack(y_train),axis=2)\n",
    "y_test_stack = np.expand_dims(np.vstack(y_test),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ea630f-9a68-4cf8-9fbd-04e0d42a3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_swap = np.array(X_train_stack).swapaxes(0,1).swapaxes(0,2)\n",
    "X_test_swap = np.array(X_test_stack).swapaxes(0,1).swapaxes(0,2)\n",
    "y_train_swap = np.array(y_train_stack).swapaxes(0,1)\n",
    "y_test_swap = np.array(y_test_stack).swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce072e1d-11e5-49ae-8f3d-5c8c0ed7fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_folder}all_model_data.npy\", 'wb') as f:\n",
    "    np.save(f, X_train_swap.astype(float))\n",
    "    np.save(f, y_train_swap.astype(float))\n",
    "    np.save(f, X_test_swap.astype(float))\n",
    "    np.save(f, y_test_swap.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5292b9-3e38-46e4-85bb-ce35fa745c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
